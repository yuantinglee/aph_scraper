{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Hansard xml version 2.0 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lxml.etree as etree\n",
    "import re\n",
    "import sys\n",
    "import datetime as dt\n",
    "from datetime import datetime \n",
    "\n",
    "import django\n",
    "import platform\n",
    "\n",
    "if platform.node() == \"srv-mcc-apsis\":\n",
    "    sys.path.append('/home/leey/tmv/BasicBrowser/')\n",
    "    xml_path = \"/home/leey/australian_parliament_downloads/downloads_coal\"\n",
    "\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/home/leey/Documents/Data/tmv/BasicBrowser/')\n",
    "    xml_path = \"/home/leey/Documents/Data/australian_parliament_downloads/downloads_coal\"\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "import cities.models as cmodels\n",
    "from django.contrib.auth.models import User\n",
    "from django.db.models import Q\n",
    "\n",
    "from find_person_in_db_aph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log file: ./parlsessions_aph_parser_output_200206_101920.log\n"
     ]
    }
   ],
   "source": [
    "# write output to file and terminal\n",
    "\n",
    "import pprint\n",
    "pretty_printer = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "output_file = \"./parlsessions_aph_parser_output_\" + time_stamp + \".log\"\n",
    "print(\"log file: {}\".format(output_file))\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(output_file, \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        #this flush method is needed for python 3 compatibility.\n",
    "        #this handles the flush command by doing nothing.\n",
    "        #you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class parse_xml_items(object):\n",
    "\n",
    "    def __init__(self, xtree, v=1, period=None, session=None):\n",
    "        self.v = v\n",
    "        self.divs = xtree.findall(\"//debate\")\n",
    "        self.pp = int(xtree.xpath(\"//parliament.no//text()\")[0])\n",
    "        self.session = int(re.findall(r'\\b\\d+\\b', xtree.xpath(\"//session.no//text()\")[0])[0])\n",
    "\n",
    "        if period is not None:\n",
    "            if period != self.pp:\n",
    "                print(\"! Warning: period number not matching: {} {}\".format(period, self.pp))\n",
    "\n",
    "        if session is not None:\n",
    "            if session != self.session:\n",
    "                print(\"! Warning: session number not matching: {} {}\".format(session, self.session))\n",
    "\n",
    "        self.date = datetime.strptime(xtree.xpath(\"//date//text()\")[0], '%Y-%m-%d')\n",
    "        #try:\n",
    "        #    self.original_source = xtree.xpath(\"//sourceDesc//url//text()\")[0]\n",
    "        #except IndexError:\n",
    "        #    self.original_source = \"NA\"\n",
    "        if self.v > 0:\n",
    "            print(\"xml with protocol {}/{} from {}\".format(self.pp, self.session, self.date))\n",
    "\n",
    "    def get_or_create_objects(self):\n",
    "\n",
    "        replace_old_documents = False\n",
    "\n",
    "        parl, created = pm.Parl.objects.get_or_create(\n",
    "            country=cmodels.Country.objects.get(name=\"Australia\"),\n",
    "            level='N')\n",
    "        if created and self.v > 0:\n",
    "            print(\"created new object for parliament\")\n",
    "\n",
    "        pp, created = pm.ParlPeriod.objects.get_or_create(\n",
    "            parliament=parl,\n",
    "            n=self.pp)\n",
    "        if created and self.v > 0:\n",
    "            print(\"created new object for legislative period\")\n",
    "\n",
    "        if replace_old_documents == True:\n",
    "            doc, created = pm.Document.objects.get_or_create(\n",
    "                parlperiod=pp,\n",
    "                doc_type=\"Parliamentary Debate\",\n",
    "                date=self.date\n",
    "            )\n",
    "            if created:\n",
    "                print(\"created new object for parliamentary debate\")\n",
    "        else:\n",
    "            doc = pm.Document(\n",
    "                parlperiod=pp,\n",
    "                doc_type=\"Parliamentary Debate\",\n",
    "                date=self.date\n",
    "            )\n",
    "\n",
    "        doc.sitting = self.session\n",
    "        #doc.text_source = \"GermaParlTEI from \" + self.original_source\n",
    "        doc.save()\n",
    "\n",
    "        # delete old utterances associated with the doc\n",
    "        doc.utterance_set.all().delete()\n",
    "        self.doc = doc\n",
    "        return doc\n",
    "\n",
    "    def create_paragraph(self, text, utterance):\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "        text = clean_text(text)\n",
    "        para = pm.Paragraph(\n",
    "            utterance=utterance,\n",
    "            text=text,\n",
    "            word_count=len(text.split()),\n",
    "            char_len=len(text)\n",
    "        )\n",
    "        para.save()\n",
    "        return para\n",
    "\n",
    "    def add_interjection(self, text, speaker, paragraph):\n",
    "        interjection = pm.Interjection(\n",
    "                paragraph=paragraph,\n",
    "                text=text\n",
    "                )\n",
    "        interjection.type = pm.Interjection.SPEECH\n",
    "        interjection.save()\n",
    "        \n",
    "        if speaker:\n",
    "            interjection.persons.add(speaker)\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.get_or_create_objects()\n",
    "        accepted_tags = ['speech', 'question', 'answer']\n",
    "        \n",
    "        ### start parsing of speeches\n",
    "        for div in self.divs:\n",
    "            if self.v > 1:\n",
    "                print(\"div type: {}\".format(div.xpath(\"type/text()\")))\n",
    "            \n",
    "            for uts in div.iter('talk.start'):\n",
    "                if uts.getparent().tag in accepted_tags:\n",
    "                    # get agenda item \n",
    "                    tops = uts.xpath('ancestor::debate/child::debateinfo/child::title/text()')[0]\n",
    "                    tops = str(tops)\n",
    "                    \n",
    "                    # create agenda item\n",
    "                    agenda_item, created = pm.AgendaItem.objects.get_or_create(\n",
    "                    title = tops,\n",
    "                    document = self.doc\n",
    "                    )\n",
    "                    \n",
    "                    for name in uts.xpath('talker//name'):\n",
    "                        if name.get('role') == 'metadata':\n",
    "                            namemd = name.text.split(', ')\n",
    "                            if len(namemd) == 1:\n",
    "                                names = namemd[0]\n",
    "                            else:\n",
    "                                names = namemd[1] + ' ' + namemd[0]\n",
    "\n",
    "                    # match speaker to database:\n",
    "                    info_dict = {}\n",
    "                    for nameidxp in uts.xpath('talker/name.id/text()'): info_dict['nameid'] = nameidxp\n",
    "                    for partyxp in uts.xpath('talker/party/text()'): info_dict['party'] = partyxp\n",
    "                    for electoratexp in uts.xpath('talker/electorate/text()'): info_dict['electorate'] = electoratexp\n",
    "                    for rolexp in uts.xpath('talker/role/text()'): info_dict['role'] = rolexp\n",
    "                    info_dict['pp'] = self.pp\n",
    "                    info_dict['session'] = self.session\n",
    "                    info_dict['date'] = self.date\n",
    "\n",
    "                    speaker = find_person_in_db_aph(names, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                    if speaker is None:\n",
    "                        print(namemd[1],namemd[0])\n",
    "\n",
    "                    ut = pm.Utterance(\n",
    "                        document=self.doc,\n",
    "                        speaker=speaker,\n",
    "                        agenda_item = agenda_item,\n",
    "                        #speaker_role=speaker_role\n",
    "                    )\n",
    "                    ut.save()\n",
    "\n",
    "                    for c in uts.iter():\n",
    "                        if self.v > 1:\n",
    "                            print(\"{}: {}\".format(c.tag, c.text))\n",
    "\n",
    "                        if c.tag == \"para\":\n",
    "                            if c.text:\n",
    "                                para = self.create_paragraph(c.text.strip(u'\\u2014'), ut)\n",
    "\n",
    "\n",
    "                    for j in uts.xpath('following-sibling::*'):\n",
    "                        if j.tag == \"para\":\n",
    "                            if j.text:\n",
    "                                para = self.create_paragraph(j.text.strip(u'\\u2014'), ut)\n",
    "\n",
    "                        elif j.tag == \"interjection\":\n",
    "                            # identify speaker here\n",
    "                            for name in j.xpath('talk.start/talker/name'):\n",
    "                                if name.get('role') == 'metadata':\n",
    "                                    namemd_inj = name.text.split(', ')\n",
    "                                    if len(namemd_inj) == 1:\n",
    "                                        names_inj = namemd_inj[0]\n",
    "                                    else:\n",
    "                                        names_inj = namemd_inj[1] + ' ' + namemd_inj[0]\n",
    "\n",
    "                                    # match speaker to database:\n",
    "                                    info_dict = {}\n",
    "                                    for nameidxp in j.xpath('talk.start/talker/name.id/text()'): info_dict['nameid'] = nameidxp\n",
    "                                    info_dict['pp'] = self.pp\n",
    "                                    info_dict['session'] = self.session\n",
    "                                    info_dict['date'] = self.date\n",
    "\n",
    "                                    speaker_inj = find_person_in_db_aph(names_inj, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                                    if speaker_inj is None:\n",
    "                                        print(namemd_inj[1], namemd_inj[0])\n",
    "\n",
    "                            for k in j.xpath('child::*/child::para'):\n",
    "                                # add interjection text and create interjection\n",
    "                                if k.text:\n",
    "                                    inj = self.add_interjection(k.text, speaker_inj, para)\n",
    "                                    \n",
    "                                else:\n",
    "                                    emptytext = \"\"\n",
    "                                    inj = self.add_interjection(emptytext, speaker_inj, para)\n",
    "\n",
    "                        elif j.tag == \"continue\":\n",
    "                            for con in j.xpath('child::*/child::para'):\n",
    "                                if con.text:\n",
    "                                    para = self.create_paragraph(con.text.strip(u'\\u2014'), ut)\n",
    "                        \n",
    "                        elif j.tag == \"motion\" or j.tag == \"quote\":\n",
    "                            for par in j.xpath('child::para'):\n",
    "                                if par.text:\n",
    "                                    para = self.create_paragraph(par.text.strip(u'\\u2014'), ut)\n",
    "                            \n",
    "                \n",
    "                elif uts.getparent().tag == \"interjection\":\n",
    "                    for l in uts.xpath('parent::interjection/preceding-sibling::debateinfo/child::type'):\n",
    "                        if l.text == \"Notices\":\n",
    "                            # speaker\n",
    "                            for name in uts.xpath('talker//name'):\n",
    "                                if name.get('role') == 'metadata':\n",
    "                                    namemd = name.text.split(', ')\n",
    "                                    if len(namemd) == 1:\n",
    "                                        names = namemd[0]\n",
    "                                    else:\n",
    "                                        names = namemd[1] + ' ' + namemd[0]\n",
    "\n",
    "                            # match speaker to database:\n",
    "                            info_dict = {}\n",
    "                            for nameidxp in uts.xpath('talker/name.id/text()'): info_dict['nameid'] = nameidxp\n",
    "                            for partyxp in uts.xpath('talker/party/text()'): info_dict['party'] = partyxp\n",
    "                            for electoratexp in uts.xpath('talker/electorate/text()'): info_dict['electorate'] = electoratexp\n",
    "                            for rolexp in uts.xpath('talker/role/text()'): info_dict['role'] = rolexp\n",
    "                            info_dict['pp'] = self.pp\n",
    "                            info_dict['session'] = self.session\n",
    "                            info_dict['date'] = self.date\n",
    "\n",
    "                            speaker = find_person_in_db_aph(names, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                            if speaker is None:\n",
    "                                print(namemd[1],namemd[0])\n",
    "\n",
    "                            ut = pm.Utterance(\n",
    "                                document=self.doc,\n",
    "                                speaker=speaker,\n",
    "                            )\n",
    "                            ut.save()\n",
    "                    \n",
    "                            # text\n",
    "                            for m in uts.xpath('child::para|following-sibling::motion/child::para|following-sibling::quote/child::para'):\n",
    "                                if m.text:\n",
    "                                    para = self.create_paragraph(m.text.strip(u'\\u2014'), ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     29
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from /home/leey/australian_parliament_downloads/downloads_coal/6602-3.xml\n",
      "xml with protocol 42/1 from 2009-03-17 00:00:00\n",
      "Person not found in database as speaker: Sid Sidebottom\n",
      "Trying to find person by name\n",
      "Found speaker by name: Sid Sidebottom\n",
      "Person not found in database as speaker: Sid Sidebottom\n",
      "Trying to find person by name\n",
      "Found speaker by name: Sid Sidebottom\n",
      "Person not found in database as speaker: Arch Bevis\n",
      "Trying to find person by name\n",
      "Found speaker by name: Arch Bevis\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# main execution script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sys.stdout = Logger()\n",
    "\n",
    "    single_doc = True\n",
    "    replace_docs = False\n",
    "\n",
    "    delete_all_words = False\n",
    "    delete_all_parties = False\n",
    "    delete_all_people = False\n",
    "    delete_additional_persons = False\n",
    "\n",
    "    if delete_all_words:\n",
    "        print(\"Deleting all documents, utterances, paragraphs and interjections.\")\n",
    "        pm.Interjection.objects.all().delete()\n",
    "        pm.Paragraph.objects.all().delete()\n",
    "        pm.Utterance.objects.all().delete()\n",
    "        pm.Document.objects.all().delete()\n",
    "        print(\"Deletion done.\")\n",
    "        \n",
    "    if delete_all_parties:\n",
    "        print(\"Deleting all parties added.\")\n",
    "        pm.Party.objects.all().delete()\n",
    "        \n",
    "    if delete_all_people:\n",
    "        print(\"Deleting all people added.\")\n",
    "        pm.Person.objects.all().delete()\n",
    "            \n",
    "    if delete_additional_persons:\n",
    "        print(\"Deleting all persons added from protocol parsing.\")\n",
    "        pm.Person.objects.filter(information_source__startswith=\"from protocol scraping\").delete()\n",
    "\n",
    "    if single_doc:\n",
    "        # single file\n",
    "        #xml_file = os.path.join(xml_path, \"163-5858.xml\") \n",
    "        #xml_file = os.path.join(xml_path, \"168-7.xml\") \n",
    "        #xml_file = os.path.join(xml_path, \"173-4969.xml\")\n",
    "        #xml_file = os.path.join(xml_path, \"6593-3.xml\")\n",
    "        xml_file = os.path.join(xml_path, \"6602-3.xml\")\n",
    "        \n",
    "        print(\"reading from {}\".format(xml_file))\n",
    "\n",
    "        xtree = etree.parse(xml_file)\n",
    "        etree.strip_tags(xtree, 'inline')\n",
    "        parser = parse_xml_items(xtree)\n",
    "\n",
    "        parser.run()\n",
    "        print(\"Done.\")\n",
    "\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# go through all scripts iteratively\n",
    "    \n",
    "for pperiod in range(13, 12, -1):\n",
    "        for session in range(0, 300):\n",
    "\n",
    "            xml_file = os.path.join(tei_path, \"{wp:02d}/BT_{wp:02d}_{sn:03d}.xml\".format(wp=pperiod, sn=session))\n",
    "\n",
    "            if os.path.isfile(xml_file):\n",
    "                print(\"reading from {}\".format(xml_file))\n",
    "\n",
    "                xtree = etree.parse(xml_file)\n",
    "                if replace_docs:\n",
    "                    pm.Document.objects.filter(parlperiod__n=pperiod, sitting=session).delete()\n",
    "                pm.Document.objects.filter(parlperiod__n=pperiod, sitting=session,\n",
    "                                           text_source__startswith=\"GermaParlTEI from \").delete()\n",
    "\n",
    "                parser = parse_tei_items(xtree, period=pperiod, session=session)\n",
    "                parser.run()\n",
    "                \n",
    "                print(\"Done\")\n",
    "                exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine results of scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826,\n",
       " {'parliament.AgendaItem': 13,\n",
       "  'parliament.Document': 1,\n",
       "  'parliament.Document_search_matches': 0,\n",
       "  'parliament.Interjection': 52,\n",
       "  'parliament.Interjection_parties': 0,\n",
       "  'parliament.Interjection_persons': 52,\n",
       "  'parliament.Paragraph': 624,\n",
       "  'parliament.Paragraph_search_matches': 0,\n",
       "  'parliament.Utterance': 84,\n",
       "  'parliament.Utterance_search_matches': 0,\n",
       "  'scoping.DocOwnership': 0,\n",
       "  'scoping.Note': 0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting specific document objects\n",
    "pm.Document.objects.filter(id=19861).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QuerySet [<Person: Frank Mossfield>]>\n"
     ]
    }
   ],
   "source": [
    "# checking name ids\n",
    "name_id = \"MK6\"\n",
    "query = pm.Person.objects.filter(aph_id=name_id)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPEAKER'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nametest = 'Harry (Mr DEPUTY SPEAKER) Jenkins'\n",
    "nametest = 'Mr SPEAKER'\n",
    "name = re.sub(r'\\([^)]*\\)', '', nametest)\n",
    "name = name.replace('  ', ' ')\n",
    "name = name.replace('Dr ', '')\n",
    "name = name.replace('Mr ', '')\n",
    "name = name.replace('The ', '')\n",
    "\n",
    "if len(name.split(' ')) > 1:\n",
    "        surname = name.split(' ')[-1]\n",
    "        firstname = name.split(' ')[0]\n",
    "else:\n",
    "    surname = name\n",
    "    firstname = ''\n",
    "\n",
    "surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sir Frederick Holder\n",
      "Sir Frederick Holder\n",
      "Sir Frederick Holder\n",
      "Charles Salmon\n",
      "Charles McDonald\n",
      "William Johnson\n",
      "Charles McDonald\n",
      "William Johnson\n",
      "William Johnson\n",
      "William Watt\n",
      "Littleton Groom\n",
      "Littleton Groom\n",
      "Norman Makin\n",
      "George Mackay\n",
      "George Bell\n",
      "George Bell\n",
      "Walter Nairn\n",
      "John Rosevear\n",
      "John Rosevear\n",
      "John Rosevear\n",
      "Archie Cameron\n",
      "Archie Cameron\n",
      "Archie Cameron\n",
      "Archie Cameron\n",
      "William Aston\n",
      "William Aston\n",
      "James Cope\n",
      "James Cope\n",
      "Gordon Scholes\n",
      "Billy Snedden\n",
      "Billy Snedden\n",
      "Billy Snedden\n",
      "Gloria Child\n",
      "Gloria Child\n",
      "Leo McLeay\n",
      "Leo McLeay\n",
      "Stephen Martin\n",
      "Robert Halverson\n",
      "Ian Sinclair\n",
      "John Andrew\n",
      "John Andrew\n",
      "David Hawker\n",
      "Peter Slipper\n",
      "Anna Burke\n",
      "Bronwyn Bishop\n",
      "John McLeay\n",
      "John McLeay\n",
      "John McLeay\n",
      "John McLeay\n",
      "Dr Henry Jenkins\n",
      "Dr Henry Jenkins\n",
      "Henry Jenkins\n",
      "Henry Jenkins\n",
      "Anthony Smith\n"
     ]
    }
   ],
   "source": [
    "for i in pm.Post.objects.all():\n",
    "    print(i.person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QuerySet [<Person: Dr Henry Jenkins>, <Person: Henry Jenkins>]>\n"
     ]
    }
   ],
   "source": [
    "query = pm.Person.objects.filter(surname='Jenkins', first_name='Henry', information_source='AustralianPoliticians')\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alfred', 'Henry', 'Henry Alfred', '(Jr)', 'Harry', 'Harry (Jr)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[1].alt_first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.strptime('2000-02-16', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rquery = pm.Post.objects.filter(\n",
    "            Q(title='Deputy Speaker') | Q(title='Second Deputy Speaker'),\n",
    "            #parlperiod__n=pp,\n",
    "            start_date__lte = date,\n",
    "            end_date__gte = date\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<Post: Post object (277)>, <Post: Post object (296)>]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Person: Henry Jenkins>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname='Jenkins'\n",
    "squery = rquery.filter(person__surname = surname)\n",
    "parl_speaker = squery.first().person\n",
    "parl_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding speaker with name id: 10000\n",
      "Finding speaker from Speaker database...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Person: John Andrew>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing function\n",
    "info_dict = {}\n",
    "info_dict['pp'] = int(39)\n",
    "info_dict['date'] = datetime.strptime(\"2000-02-16\", \"%Y-%m-%d\")\n",
    "info_dict['nameid'] = \"10000\"\n",
    "names = 'Mr SPEAKER'\n",
    "\n",
    "sp = find_person_in_db_aph(names, add_info= info_dict, verbosity = 2)\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Person: Henry Jenkins>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = int(39)\n",
    "date = datetime.strptime(\"2000-02-16\", \"%Y-%m-%d\")\n",
    "\n",
    "rquery = pm.Post.objects.filter(\n",
    "            Q(title='Deputy Speaker') | Q(title='Second Deputy Speaker'),\n",
    "            parlperiod__n=pp,\n",
    "            start_date__lte = date,\n",
    "            end_date__gte = date\n",
    "            )\n",
    "rquery[1].person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peter Sid', 'Peter', 'Sid']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname = \"Sidebottom\"\n",
    "pm.Person.objects.filter(surname=surname)[0].alt_first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'849'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.Person.objects.filter(surname=\"Sidebottom\",alt_first_names__contains=[\"Sid\"])[0].aph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<Person: Peter Sidebottom>]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.Person.objects.filter(aph_id=\"849\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmv_yt",
   "language": "python",
   "name": "tmv_yt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
