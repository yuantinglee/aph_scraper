{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for Hansard xml version 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slow version of gensim.models.doc2vec is being used\n",
      "Slow version of Fasttext is being used\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lxml.etree as etree\n",
    "import re\n",
    "import sys\n",
    "import datetime as dt\n",
    "from datetime import datetime \n",
    "\n",
    "import django\n",
    "import platform\n",
    "\n",
    "if platform.node() == \"srv-mcc-apsis\":\n",
    "    sys.path.append('/home/leey/tmv/BasicBrowser/')\n",
    "    xml_path = \"/home/leey/australian_parliament_downloads/downloads_coal\"\n",
    "\n",
    "else:\n",
    "    # local paths\n",
    "    sys.path.append('/home/leey/Documents/Data/tmv/BasicBrowser/')\n",
    "    xml_path = \"/home/leey/Documents/Data/australian_parliament_downloads/downloads_coal\"\n",
    "\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"BasicBrowser.settings\")\n",
    "django.setup()\n",
    "\n",
    "# import from appended path\n",
    "import parliament.models as pm\n",
    "import cities.models as cmodels\n",
    "from django.db.models import Q\n",
    "\n",
    "from find_person_in_db_aph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log file: ./parlsessions_aph_parser_output_200303_155520.log\n"
     ]
    }
   ],
   "source": [
    "# write output to file and terminal\n",
    "\n",
    "import pprint\n",
    "pretty_printer = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "output_file = \"./parlsessions_aph_parser_output_\" + time_stamp + \".log\"\n",
    "print(\"log file: {}\".format(output_file))\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(output_file, \"a\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        #this flush method is needed for python 3 compatibility.\n",
    "        #this handles the flush command by doing nothing.\n",
    "        #you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class parse_xml_items(object):\n",
    "\n",
    "    def __init__(self, xtree, v=1, period=None, session=None):\n",
    "        self.v = v\n",
    "        self.divs = xtree.findall(\"//chamber.xscript//debate\")\n",
    "        self.pp = int(xtree.xpath(\"//parliament.no//text()\")[0])\n",
    "        self.session = int(re.findall(r'\\b\\d+\\b', xtree.xpath(\"//session.no//text()\")[0])[0])\n",
    "\n",
    "        if period is not None:\n",
    "            if period != self.pp:\n",
    "                print(\"! Warning: period number not matching: {} {}\".format(period, self.pp))\n",
    "\n",
    "        if session is not None:\n",
    "            if session != self.session:\n",
    "                print(\"! Warning: session number not matching: {} {}\".format(session, self.session))\n",
    "\n",
    "        self.date = datetime.strptime(xtree.xpath(\"//date//text()\")[0], '%Y-%m-%d')\n",
    "\n",
    "        if self.v > 0:\n",
    "            print(\"xml with protocol {}/{} from {}\".format(self.pp, self.session, self.date))\n",
    "\n",
    "    def get_or_create_objects(self):\n",
    "\n",
    "        replace_old_documents = False\n",
    "\n",
    "        parl, created = pm.Parl.objects.get_or_create(\n",
    "            country=cmodels.Country.objects.get(name=\"Australia\"),\n",
    "            level='N')\n",
    "        if created and self.v > 0:\n",
    "            print(\"created new object for parliament\")\n",
    "\n",
    "        pp, created = pm.ParlPeriod.objects.get_or_create(\n",
    "            parliament=parl,\n",
    "            n=self.pp)\n",
    "        if created and self.v > 0:\n",
    "            print(\"created new object for legislative period\")\n",
    "\n",
    "        if replace_old_documents == True:\n",
    "            doc, created = pm.Document.objects.get_or_create(\n",
    "                parlperiod=pp,\n",
    "                doc_type=\"Parliamentary Debate\",\n",
    "                date=self.date\n",
    "            )\n",
    "            if created:\n",
    "                print(\"created new object for parliamentary debate\")\n",
    "        else:\n",
    "            doc = pm.Document(\n",
    "                parlperiod=pp,\n",
    "                doc_type=\"Parliamentary Debate\",\n",
    "                date=self.date\n",
    "            )\n",
    "\n",
    "        doc.sitting = self.session\n",
    "        #doc.text_source = \"GermaParlTEI from \" + self.original_source\n",
    "        doc.save()\n",
    "\n",
    "        # delete old utterances associated with the doc\n",
    "        doc.utterance_set.all().delete()\n",
    "        self.doc = doc\n",
    "        return doc\n",
    "\n",
    "    def create_paragraph(self, text, utterance):\n",
    "        text = text.replace(\"\\n\\n\", \"\\n\")\n",
    "        text = clean_text(text)\n",
    "        para = pm.Paragraph(\n",
    "            utterance=utterance,\n",
    "            text=text,\n",
    "            word_count=len(text.split()),\n",
    "            char_len=len(text)\n",
    "        )\n",
    "        para.save()\n",
    "        return para\n",
    "\n",
    "    def add_interjection(self, text, speaker, paragraph):\n",
    "        interjection = pm.Interjection(\n",
    "                paragraph=paragraph,\n",
    "                text=text\n",
    "                )\n",
    "        interjection.type = pm.Interjection.SPEECH\n",
    "        interjection.save()\n",
    "        \n",
    "        if speaker:\n",
    "            interjection.persons.add(speaker)\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        self.get_or_create_objects()\n",
    "        accepted_tags = ['speech', 'question', 'answer']\n",
    "        \n",
    "        ### start parsing of speeches\n",
    "        for div in self.divs:\n",
    "            if self.v > 1:\n",
    "                print(\"div type: {}\".format(div.xpath(\"type/text()\")))\n",
    "            \n",
    "            for uts in div.iter('talk.start'):\n",
    "                if uts.getparent().tag in accepted_tags:\n",
    "                    # get agenda item \n",
    "                    tops = uts.xpath('ancestor::debate/child::debateinfo/child::title/text()')[0]\n",
    "                    tops = str(tops)\n",
    "                    \n",
    "                    # create agenda item\n",
    "                    agenda_item, created = pm.AgendaItem.objects.get_or_create(\n",
    "                    title = tops,\n",
    "                    document = self.doc\n",
    "                    )\n",
    "                    \n",
    "                    for name in uts.xpath('talker//name'):\n",
    "                        if name.get('role') == 'metadata':\n",
    "                            namemd = name.text.split(', ')\n",
    "                            if len(namemd) == 1:\n",
    "                                names = namemd[0]\n",
    "                            else:\n",
    "                                names = namemd[1] + ' ' + namemd[0]\n",
    "\n",
    "                    # match speaker to database:\n",
    "                    info_dict = {}\n",
    "                    for nameidxp in uts.xpath('talker/name.id/text()'): info_dict['nameid'] = nameidxp\n",
    "                    for partyxp in uts.xpath('talker/party/text()'): info_dict['party'] = partyxp\n",
    "                    for electoratexp in uts.xpath('talker/electorate/text()'): info_dict['electorate'] = electoratexp\n",
    "                    for rolexp in uts.xpath('talker/role/text()'): info_dict['role'] = rolexp\n",
    "                    info_dict['pp'] = self.pp\n",
    "                    info_dict['session'] = self.session\n",
    "                    info_dict['date'] = self.date\n",
    "\n",
    "                    speaker = find_person_in_db_aph(names, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                    if speaker is None:\n",
    "                        print(namemd[1],namemd[0])\n",
    "\n",
    "                    ut = pm.Utterance(\n",
    "                        document=self.doc,\n",
    "                        speaker=speaker,\n",
    "                        agenda_item = agenda_item,\n",
    "                        #speaker_role=speaker_role\n",
    "                    )\n",
    "                    ut.save()\n",
    "                    \n",
    "                    for j in uts.xpath('following-sibling::talk.text'):\n",
    "                        for k in j.iter('span'):\n",
    "                            if k.get('class') == \"HPS-Normal\" or k.get('class') == \"HPS-Small\" or k.get('class') == None:\n",
    "                                if k.text is not None:\n",
    "                                    text1 = re.sub('\\)\\:', '', k.text.strip()).strip()\n",
    "                                    para = self.create_paragraph(text1, ut)\n",
    "                            if k.get('class') == \"HPS-Normal\" or k.get('class') == \"HPS-Small\" or k.get('class') == None or k.get('class') == \"HPS-Time\":\n",
    "                                if k.tail:\n",
    "                                    text2 = re.sub('\\)\\:', '', k.tail.strip()).strip()\n",
    "                                    para = self.create_paragraph(text2, ut)\n",
    "\n",
    "                            for a in k.iter('a'):\n",
    "                                if a.get(\"type\") == \"MemberInterjecting\":\n",
    "                                    # identify speaker\n",
    "                                    for name in a.iter('span'): namemd_inj = name.text.strip()\n",
    "                                    names_inj = namemd_inj[0].strip(':')\n",
    "\n",
    "                                    # match speaker to database:\n",
    "                                    info_dict = {}\n",
    "                                    info_dict['nameid'] = a.get(\"href\")\n",
    "                                    info_dict['pp'] = self.pp\n",
    "                                    info_dict['session'] = self.session\n",
    "                                    info_dict['date'] = self.date\n",
    "\n",
    "                                    speaker_inj = find_person_in_db_aph(names_inj, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                                    if speaker_inj is None:\n",
    "                                        print(namemd_inj[1], namemd_inj[0])\n",
    "\n",
    "                                    # add text\n",
    "                                    inj = self.add_interjection(a.tail.strip(), speaker_inj, para)\n",
    "\n",
    "                                elif a.get(\"type\") == \"MemberContinuation\": \n",
    "                                    # create new utterance due to inconsistency in \"continuing\" members\n",
    "                                    # identify speaker\n",
    "                                    for name in a.iter('span'): namemd_con = name.text.strip()\n",
    "                                    names_con = namemd_con[0].strip(':')\n",
    "\n",
    "                                    # match speaker to database:\n",
    "                                    info_dict = {}\n",
    "                                    info_dict['nameid'] = a.get(\"href\")\n",
    "                                    info_dict['pp'] = self.pp\n",
    "                                    info_dict['session'] = self.session\n",
    "                                    info_dict['date'] = self.date\n",
    "\n",
    "                                    speaker_con = find_person_in_db_aph(names_con, add_info=info_dict, verbosity=self.v)\n",
    "\n",
    "                                    if speaker_con is None:\n",
    "                                        print(namemd_con[1], namemd_con[0])\n",
    "                                    \n",
    "                                    ut = pm.Utterance(\n",
    "                                    document=self.doc,\n",
    "                                    speaker=speaker_con,\n",
    "                                    agenda_item = agenda_item,\n",
    "                                    )\n",
    "                                    ut.save()\n",
    "                                    \n",
    "                                    para = self.create_paragraph(a.tail.strip(), ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     29
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from /home/leey/Documents/Data/australian_parliament_downloads/downloads_coal/House_of_Representatives_2011_05_10_10_Official.xml\n",
      "xml with protocol 43/1 from 2011-05-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# main execution script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    sys.stdout = Logger()\n",
    "\n",
    "    single_doc = True\n",
    "    replace_docs = False\n",
    "\n",
    "    delete_all_words = False\n",
    "    delete_all_parties = False\n",
    "    delete_all_people = False\n",
    "    delete_additional_persons = False\n",
    "\n",
    "    if delete_all_words:\n",
    "        print(\"Deleting all documents, utterances, paragraphs and interjections.\")\n",
    "        pm.Interjection.objects.all().delete()\n",
    "        pm.Paragraph.objects.all().delete()\n",
    "        pm.Utterance.objects.all().delete()\n",
    "        pm.Document.objects.all().delete()\n",
    "        print(\"Deletion done.\")\n",
    "        \n",
    "    if delete_all_parties:\n",
    "        print(\"Deleting all parties added.\")\n",
    "        pm.Party.objects.all().delete()\n",
    "        \n",
    "    if delete_all_people:\n",
    "        print(\"Deleting all people added.\")\n",
    "        pm.Person.objects.all().delete()\n",
    "            \n",
    "    if delete_additional_persons:\n",
    "        print(\"Deleting all persons added from protocol parsing.\")\n",
    "        pm.Person.objects.filter(information_source__startswith=\"from protocol scraping\").delete()\n",
    "\n",
    "    if single_doc:\n",
    "        # single file\n",
    "        #xml_file = os.path.join(xml_path, \"163-5858.xml\") \n",
    "        #xml_file = os.path.join(xml_path, \"168-7.xml\") \n",
    "        #xml_file = os.path.join(xml_path, \"173-4969.xml\")\n",
    "        #xml_file = os.path.join(xml_path, \"6593-3.xml\")\n",
    "        #xml_file = os.path.join(xml_path, \"6602-3.xml\")\n",
    "        xml_file = os.path.join(xml_path, \"House_of_Representatives_2011_05_10_10_Official.xml\")\n",
    "        \n",
    "        print(\"reading from {}\".format(xml_file))\n",
    "\n",
    "        xtree = etree.parse(xml_file)\n",
    "        etree.strip_tags(xtree, 'inline')\n",
    "        parser = parse_xml_items(xtree)\n",
    "\n",
    "        parser.run()\n",
    "        print(\"Done.\")\n",
    "\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# go through all scripts iteratively\n",
    "    \n",
    "for pperiod in range(13, 12, -1):\n",
    "        for session in range(0, 300):\n",
    "\n",
    "            xml_file = os.path.join(tei_path, \"{wp:02d}/BT_{wp:02d}_{sn:03d}.xml\".format(wp=pperiod, sn=session))\n",
    "\n",
    "            if os.path.isfile(xml_file):\n",
    "                print(\"reading from {}\".format(xml_file))\n",
    "\n",
    "                xtree = etree.parse(xml_file)\n",
    "                if replace_docs:\n",
    "                    pm.Document.objects.filter(parlperiod__n=pperiod, sitting=session).delete()\n",
    "                pm.Document.objects.filter(parlperiod__n=pperiod, sitting=session,\n",
    "                                           text_source__startswith=\"GermaParlTEI from \").delete()\n",
    "\n",
    "                parser = parse_tei_items(xtree, period=pperiod, session=session)\n",
    "                parser.run()\n",
    "                \n",
    "                print(\"Done\")\n",
    "                exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine results of scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527,\n",
       " {'parliament.Document_search_matches': 0,\n",
       "  'scoping.Note': 0,\n",
       "  'scoping.DocOwnership': 0,\n",
       "  'parliament.Utterance_search_matches': 0,\n",
       "  'parliament.Paragraph_search_matches': 0,\n",
       "  'parliament.Interjection_parties': 0,\n",
       "  'parliament.Interjection_persons': 9,\n",
       "  'parliament.AgendaItem': 13,\n",
       "  'parliament.Interjection': 9,\n",
       "  'parliament.Paragraph': 1425,\n",
       "  'parliament.Utterance': 70,\n",
       "  'parliament.Document': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting specific document objects\n",
    "pm.Document.objects.filter(id=3572).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QuerySet [<Person: Frank Mossfield>]>\n"
     ]
    }
   ],
   "source": [
    "# checking name ids\n",
    "name_id = \"MK6\"\n",
    "query = pm.Person.objects.filter(aph_id=name_id)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
